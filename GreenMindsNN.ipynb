{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_detection_for_objects.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RKoy7yD2FYEl","colab_type":"text"},"source":["#Imports\n","Everyting with torch is for PyTorch which is our system for the neural network\n","\n","Numpy, pandas, and matlab is for structuring and visualisation of data\n","%matplotlib and %config is used to show graphs in line in the google collab view"]},{"cell_type":"code","metadata":{"id":"YZWlzbb8E8IC","colab_type":"code","colab":{}},"source":["# imports related to PyTorch\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from collections import OrderedDict\n","\n","# python tools\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","# other\n","import json\n","from PIL import Image\n","\n","# google collab specific\n","from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wU1ERTR9Fwtr","colab_type":"text"},"source":["#Loading of data\n","We are using `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The dataset is split into three parts, training, validation, and testing. For the training, there has been applyed transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n","\n","The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this we don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n","\n","The pre-trained networks we'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three set we'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's [0.485, 0.456, 0.406] and for the standard deviations [0.229, 0.224, 0.225], calculated from the ImageNet images. These values will shift each color channel to be centered at 0 and range from -1 to 1."]},{"cell_type":"markdown","metadata":{"id":"sBKjNK6BF3ea","colab_type":"text"},"source":["#### Gets acces to the google drive folder\n","\\* only run if using google collab"]},{"cell_type":"code","metadata":{"id":"sETuvxkcF0MU","colab_type":"code","outputId":"5b601975-13cf-4ad2-c48b-7248323a063e","executionInfo":{"status":"ok","timestamp":1579033279430,"user_tz":360,"elapsed":360,"user":{"displayName":"Christian Rasmussen","photoUrl":"","userId":"14042458835072871480"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# gets acces to the google drive folder\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p2B3QYNNUkBL","colab_type":"text"},"source":["#### getting the data\n","we are using the data loader class from PyTorch which means that the images should be arranged following this structure:\n","\n","* class 'dog'\n","    * root/dog/xxx.png\n","    * root/dog/xxy.png\n","    * root/dog/xxz.png\n","* class 'cat'\n","    * root/cat/123.png\n","    * root/cat/nsdf3.png\n","    * root/cat/asd932_.png\n","\n"]},{"cell_type":"code","metadata":{"id":"QZ0RSSkEUlaS","colab_type":"code","colab":{}},"source":["# paths to data needs to get changed, for new data location \n","path = '/content/gdrive/My Drive/cs3_Rasmussen/Collab/GreenMinds-recycling-bot/Fruits_data'\n","\n","data_dir = {\n","    'train': path + '/train',\n","    'valid': path+ '/valid',\n","    'test': path + '/test'   \n","}\n","\n","# Defines the transforms for the training, validation, and testing sets\n","data_transforms = {\n","    'train': transforms.Compose([\n","                transforms.RandomRotation(30),\n","                transforms.RandomResizedCrop(224),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","            ]),\n","    'valid': transforms.Compose([\n","                transforms.Resize(255),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","            ]),\n","    'test': transforms.Compose([\n","                transforms.Resize(255),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","            ])\n","}\n","\n","# Loads the datasets with ImageFolder\n","data_datasets = {\n","    'train': datasets.ImageFolder(data_dir['train'], transform=data_transforms['train']),\n","    'valid': datasets.ImageFolder(data_dir['valid'], transform=data_transforms['valid'])\n"," #   'test': datasets.ImageFolder(data_dir['test'], transform=data_transforms['test'])\n","}\n","\n","# Using the image datasets and the trainforms, defines the dataloaders\n","# we are using batch_size of 32 to make sure not to run out of memory on google collab\n","data_dataloaders = {\n","    'train': torch.utils.data.DataLoader(data_datasets['train'], batch_size=32, shuffle=True),\n","    'valid': torch.utils.data.DataLoader(data_datasets['valid'], batch_size=32)\n","    #'test': torch.utils.data.DataLoader(data_datasets['test'], batch_size=32)\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMYzAzS6W4Ah","colab_type":"text"},"source":["# Building the classifier"]},{"cell_type":"markdown","metadata":{"id":"gsbYMGm_W_Co","colab_type":"text"},"source":["Getting our pretrained model"]},{"cell_type":"code","metadata":{"id":"FM9_SYcBW514","colab_type":"code","colab":{}},"source":["model = models.densenet121(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1v5kL6IXBOF","colab_type":"text"},"source":["Freezing the parameters so we wont backprop through them"]},{"cell_type":"code","metadata":{"id":"l3E2BUpZW7uq","colab_type":"code","colab":{}},"source":["for param in model.parameters():\n","    param.requires_gradu = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pUSni9cYXFRL","colab_type":"text"},"source":["Creating a new classifier for transfor learning"]},{"cell_type":"code","metadata":{"id":"I1Df1YD1W8AL","colab_type":"code","colab":{}},"source":["prediction_size = 6\n","\n","classifier = nn.Sequential(OrderedDict([\n","    ('fc_1', nn.Linear(1024, 512)),\n","    ('relu_1', nn.ReLU()),\n","    ('dropout_1', nn.Dropout(.2)),\n","    ('fc_2', nn.Linear(512, 256)),\n","    ('relu_2', nn.ReLU()),\n","    ('dropout_2', nn.Dropout(.2)),\n","    ('fc_3', nn.Linear(256, prediction_size)),\n","    ('output', nn.LogSoftmax(dim=1))\n","]))\n","\n","model.classifier = classifier"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ieJGINOwXJ17","colab_type":"text"},"source":["Checks if cuda is enabled, and sends our model to the gpu if avaliable"]},{"cell_type":"code","metadata":{"id":"b6-wWRRWW8MH","colab_type":"code","outputId":"da918343-5fab-44b6-d8e9-144bc2168155","executionInfo":{"status":"error","timestamp":1579033298331,"user_tz":360,"elapsed":334,"user":{"displayName":"Christian Rasmussen","photoUrl":"","userId":"14042458835072871480"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-78e739c00ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}]},{"cell_type":"markdown","metadata":{"id":"ZCSwlVKjXMpY","colab_type":"text"},"source":["Defining hyper parameters"]},{"cell_type":"code","metadata":{"id":"etCKx2ZOW8X1","colab_type":"code","colab":{}},"source":["criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n","\n","epochs = 1\n","steps = 0\n","print_every_step = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bvyZ2rX0XQCu","colab_type":"text"},"source":["Creating our training loop"]},{"cell_type":"code","metadata":{"id":"ftmXa4SSXOSc","colab_type":"code","outputId":"baf80b81-6ab0-413f-a167-7ee96e7228c1","executionInfo":{"status":"error","timestamp":1579031983646,"user_tz":360,"elapsed":11558,"user":{"displayName":"Christian Rasmussen","photoUrl":"","userId":"14042458835072871480"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["# sets our model to train mode\n","model.train()\n","# sends our model to the device (cpu/gpu)\n","model = model.to(device)\n","\n","# for graphing\n","train_losses, test_losses = [], []\n","\n","# runs through set amount of epochs\n","for epoch in range(epochs):\n","    # holds our runnning loss\n","    running_loss = 0\n","\n","    # loops over our train data\n","    for inputs, labels in data_dataloaders['train']:\n","        # add 1 to the number of steps done\n","        steps += 1\n","        \n","        # moves input- and labels- tensors to the device (cpu/gpu)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        # resets our optimizer\n","        optimizer.zero_grad()\n","        # gets our log probabilities from our model\n","        logps = model.forward(inputs)\n","        # calculates the loss using our criterion\n","        loss = criterion(logps, labels)\n","        # backprobagates to update our weights\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # adds our loss to the total loss, between validation\n","        running_loss += loss.item()\n","        \n","        # calculates our models current accuracy each x steps\n","        if steps % print_every_step == 0:\n","            # holds our test loss\n","            test_loss = 0\n","            # holds our total accuracy\n","            accuracy = 0\n","            \n","            # sets our model to eval, to stop dropout\n","            model.eval()\n","            \n","            # stops our optimizer for better performance\n","            with torch.no_grad():\n","                # loops through our validation data\n","                for inputs, labels in data_dataloaders['valid']:\n","                    # moves input- and labels- tensors to the device (cpu/gpu)\n","                    inputs, labels = inputs.to(device), labels.to(device)\n","                    \n","                    # gets our log probabilities from our model\n","                    logps = model.forward(inputs)\n","                    # calculates the loss using our criterion\n","                    batch_loss = criterion(logps, labels)\n","                    # adds our loss to the total loss validation loss\n","                    test_loss += batch_loss.item()\n","                    \n","                    # ---Calcualtes the accuracy\n","                    # converts to probabilities\n","                    ps = torch.exp(logps)\n","                    # gets the top prediction\n","                    top_p, top_class = ps.topk(1, dim=1)\n","                    # Check if it is equal to the label\n","                    equals = top_class == labels.view(*top_class.shape)\n","                    # adds our accuracy this step to the total validation accuracy\n","                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n","            \n","            train_losses.append(running_loss/print_every_step)\n","            test_losses.append(test_loss/len(data_dataloaders['valid']))\n","            \n","            # Prints out data about our current model accuracy and losses\n","            print(f\"Epoch {epoch+1}/{epochs}.. \"\n","                  f\"Train loss: {running_loss/print_every_step:.3f}.. \"\n","                  f\"Test loss: {test_loss/len(data_dataloaders['valid']):.3f}.. \"\n","                  f\"Test accuracy: {accuracy/len(data_dataloaders['valid']):.10f}\")\n","            \n","            # resets our running loss\n","            running_loss = 0\n","            # resets our model to train mode\n","            model.train()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-6f6ee7b79ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# moves input- and labels- tensors to the device (cpu/gpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# resets our optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}]},{"cell_type":"markdown","metadata":{"id":"Cqii0h_nc6Up","colab_type":"text"},"source":["#### Plots training vs validation loss\n","used to check for over / under fitting"]},{"cell_type":"code","metadata":{"id":"Dg6ZoFqmo31O","colab_type":"code","cellView":"both","colab":{}},"source":["plt.plot(train_losses, label='Training loss')\n","plt.plot(test_losses, label='Validation loss')\n","plt.ylim(bottom=0)\n","plt.legend(frameon=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZE_hWZZz__h","colab_type":"text"},"source":["# Validation on the test set"]},{"cell_type":"code","metadata":{"id":"OITJ0AD9z__i","colab_type":"code","colab":{}},"source":["# holds our total test loss\n","test_loss = 0\n","# holds our total accuracy\n","accuracy = 0\n","# sends our model to the device (cpu/gpu)\n","model = model.to(device)\n","# sets our model to eval mode\n","model.eval()\n","\n","# stops our optimizer for better performance\n","with torch.no_grad():\n","    # loops over our test data\n","    for inputs, labels in data_dataloaders['test']:\n","        # moves input- and labels- tensors to the device (cpu/gpu)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        # gets our log probabilities from our model\n","        logps = model.forward(inputs)\n","        \n","        # --- Calcualtes the accuracy\n","        # converts to probabilities\n","        ps = torch.exp(logps)\n","        # gets the top prediction\n","        top_p, top_class = ps.topk(1, dim = 1)\n","        # Check if it is equal to the label\n","        equals = top_class == labels.view(*top_class.shape)\n","        # adds our accuracy this step to the total test accuracy\n","        accuracy += torch.mean(equals.type(torch.FloatTensor))\n","\n","# prints out the final result\n","print('Test accuracy: {}'.format(accuracy / len(data_dataloaders['test'])))"],"execution_count":0,"outputs":[]}]}